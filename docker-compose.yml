version: '3.8'

services:
  spark-master:
    image: bitnami/spark:3.5.0
    container_name: spark_master
    hostname: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      # Otimização vinda do Claude: Ensina ao Spark que ele só tem 2 cores lógicos
      - SPARK_MASTER_OPTS=-Dspark.deploy.defaultCores=2
      - SPARK_DAEMON_MEMORY=512m
    ports:
      - "8080:8080"
      - "7077:7077"
      - "4040:4040"
    volumes:
      - ./data:/opt/spark-data
      - ./scripts:/opt/spark-apps
      - ./analysis:/opt/spark-analysis
      - ./config:/opt/spark/conf
      - ./logs:/opt/spark/logs
      # ✅ CRÍTICO: Essencial para GraphFrames
      - ./checkpoints:/opt/spark-checkpoints
    networks:
      - spark-network
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  spark-worker:
    image: bitnami/spark:3.5.0
    container_name: spark_worker_1
    hostname: spark-worker-1
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      # Limpeza automática de logs/work dirs
      - SPARK_WORKER_OPTS=-Dspark.worker.cleanup.enabled=true -Dspark.worker.cleanup.interval=1800
    depends_on:
      spark-master:
        condition: service_healthy
    volumes:
      - ./data:/opt/spark-data
      - ./scripts:/opt/spark-apps
      - ./logs:/opt/spark/logs
      # ✅ CRÍTICO: Worker precisa acessar o mesmo checkpoint
      - ./checkpoints:/opt/spark-checkpoints
    networks:
      - spark-network
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G

networks:
  spark-network:
    driver: bridge